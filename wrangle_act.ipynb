{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Rates Data Wrangling\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#gather\">Gathering</a></li>\n",
    "<li><a href=\"#assess\">Assessing</a></li>\n",
    "<li><a href=\"#clean\">Cleaning</a></li>\n",
    "<li><a href=\"#analyze&visualize\">Analyze and Visualize</a></li>\n",
    "<li><a href=\"#conclusion\">Conclusion</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "The dataset is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog.\n",
    "\n",
    "The data wrangling process will consist of 3 main steps. They are:\n",
    "1. **Data gathering** - The data can be gathered in many ways including web scraping, using APIs etc. The data can be gathered from a single source or from many different sources.\n",
    "2. **Assessing the data** - The data needs to assessed for quality and tidiness issues. This can be done visually and/or programatically.\n",
    "3. **Cleaning the data** - Based on the assessment, the data is cleaned and tested to make sure all the issues identified are resolved.\n",
    "\n",
    "**Analyze & Visualize**\n",
    "<br/>\n",
    "Finally, the wrangled data is analyzed and visualized in an effective and insightful manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Importing all necessary packages for the data wrangling and analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gather'></a>\n",
    "## Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The data for this analysis is to be gathered from multiple sources. They are:\n",
    ">\n",
    "> 1. The WeRateDogs Twitter archive is enhanced and provided. This file (**twitter_archive_enhanced.csv**) just needs to be downloaded.\n",
    ">\n",
    "> 2. The tweet image predictions, i.e., what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network. This file (**image_predictions.tsv**) is hosted on Udacity's servers and should be downloaded programmatically.\n",
    ">\n",
    "> 3. Additional required and interesting data is to be obtained by querying the Twitter API for each tweet's JSON data and store each tweet's entire set of JSON data in a file (**tweet_json.txt**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*The file containing enhanced twitter archive (twitter_archive_enhanced.csv) has been manually downloaded and is available in the directory. The tweet image predictions file (image_predictions.tsv) is to be downloaded programmatically using the URL provided.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the URL provided in a variable\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "\n",
    "# getting the response from the URL using requests library \n",
    "response = requests.get(url)\n",
    "\n",
    "# with keyword ensures that the file is closed immediately the desired operation is complete\n",
    "# file is opened for writing in binary mode\n",
    "with open('image_predictions.tsv', 'wb') as file:\n",
    "    # content of the response is written to the file\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*The file containing the image predictions is successfully saved in the working directory. The additional data needs to be downloaded by querying the Twitter API using tweepy library. In order to do that, create a twitter developer account after signing in/up. Once the account is created, the consumer keys and authentication tokens will be available for use.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*It is not safe to expose the consumer keys and authentication tokens via code. Hence, a config file can used and imported in this notebook. (In order to execute the rest of the notebook, please fill in the necessary details in the config.py file)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Authenticate using the consumer keys and set the access tokens.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepy.api.API at 0x7ff76250afd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an OAuthHandler instance\n",
    "auth = tweepy.OAuthHandler(config.API_KEY, config.API_SECRET_KEY)\n",
    "# set the access tokens\n",
    "auth.set_access_token(config.ACCESS_TOKEN, config.ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# create the API instance\n",
    "# wait_on_rate_limit – whether or not to automatically wait for rate limits to replenish\n",
    "# wait_on_rate_limit_notify – whether or not to print a notification when Tweepy is waiting for rate limits to replenish\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*The API instance is created and ready for use now.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*The ID corresponding to each tweet is required in order to access the additional details of the tweet. These IDs are present in the twitter-archive-enhanced.csv file. Read the file and store as dataframe for further use.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-31 00:18:03 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891815181...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Archie</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-30 15:58:51 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Darla. She commenced a snooze mid meal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891689557...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Darla</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-29 16:00:24 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Franklin. He would like you to stop ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891327558...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "1  892177421306343426                    NaN                  NaN   \n",
       "2  891815181378084864                    NaN                  NaN   \n",
       "3  891689557279858688                    NaN                  NaN   \n",
       "4  891327558926688256                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "2  2017-07-31 00:18:03 +0000   \n",
       "3  2017-07-30 15:58:51 +0000   \n",
       "4  2017-07-29 16:00:24 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...                  NaN   \n",
       "3  This is Darla. She commenced a snooze mid meal...                  NaN   \n",
       "4  This is Franklin. He would like you to stop ca...                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "1  https://twitter.com/dog_rates/status/892177421...                13   \n",
       "2  https://twitter.com/dog_rates/status/891815181...                12   \n",
       "3  https://twitter.com/dog_rates/status/891689557...                13   \n",
       "4  https://twitter.com/dog_rates/status/891327558...                12   \n",
       "\n",
       "   rating_denominator      name doggo floofer pupper puppo  \n",
       "0                  10   Phineas  None    None   None  None  \n",
       "1                  10     Tilly  None    None   None  None  \n",
       "2                  10    Archie  None    None   None  None  \n",
       "3                  10     Darla  None    None   None  None  \n",
       "4                  10  Franklin  None    None   None  None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the file twitter-archive-enhanced.csv and store it in a dataframe \n",
    "twitter_archive_df = pd.read_csv('twitter-archive-enhanced.csv', index_col=None, encoding = 'utf-8')\n",
    "twitter_archive_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet ID: 888202515573088257 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 873697596434513921 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 872668790621863937 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 872261713294495745 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 869988702071779329 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 866816280283807744 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 861769973181624320 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 856602993587888130 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 851953902622658560 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 845459076796616705 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 844704788403113984 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 842892208864923648 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 837366284874571778 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 837012587749474308 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 829374341691346946 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 827228250799742977 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 812747805718642688 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 802247111496568832 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 779123168116150273 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 775096608509886464 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 771004394259247104 - [{'code': 179, 'message': 'Sorry, you are not authorized to see this status.'}]\n",
      "Tweet ID: 770743923962707968 - [{'code': 144, 'message': 'No status found with that ID.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet ID: 759566828574212096 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 754011816964026368 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Tweet ID: 680055455951884288 - [{'code': 144, 'message': 'No status found with that ID.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 2356\n",
      "Time taken: 34.96101151307424 minutes\n",
      "Total number of failed tweets: 25\n",
      "List of failed tweet IDs: [888202515573088257, 873697596434513921, 872668790621863937, 872261713294495745, 869988702071779329, 866816280283807744, 861769973181624320, 856602993587888130, 851953902622658560, 845459076796616705, 844704788403113984, 842892208864923648, 837366284874571778, 837012587749474308, 829374341691346946, 827228250799742977, 812747805718642688, 802247111496568832, 779123168116150273, 775096608509886464, 771004394259247104, 770743923962707968, 759566828574212096, 754011816964026368, 680055455951884288]\n"
     ]
    }
   ],
   "source": [
    "total_number_of_tweets = len(twitter_archive_df.tweet_id)\n",
    "number_of_failures = 0\n",
    "failed_tweets_dict = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# opening a text file in write mode and writing the JSON containing additional details of the tweet \n",
    "with open('tweet_json.txt', 'w') as txt_file:\n",
    "    # looping over all the tweets whose IDs are present in the twitter_archive_df dataframe\n",
    "    for tweet_id in twitter_archive_df.tweet_id:    \n",
    "        try:\n",
    "            # get a single status specified by the ID parameter\n",
    "            # extended tweet mode gives the entire untruncated text of the Tweet\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            json.dump(tweet._json, txt_file)\n",
    "            txt_file.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "            number_of_failures += 1\n",
    "            failed_tweets_dict.append(tweet_id)\n",
    "            print('Tweet ID:', tweet_id, '-', e)\n",
    "            continue\n",
    "\n",
    "print('Total number of tweets:', total_number_of_tweets)\n",
    "print('Time taken:', (time.time()-start)/60, 'minutes')\n",
    "print('Total number of failed tweets:', number_of_failures)\n",
    "print('List of failed tweet IDs:', failed_tweets_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Below are the explanations of the status codes for the errors:*<br/>\n",
    ">*Status code 144 - Corresponds with HTTP 404. The requested Tweet ID is not found (if it existed, it was probably deleted)*<br/>\n",
    ">*Status code 179 - Corresponds with HTTP 403. Thrown when a Tweet cannot be viewed by the authenticating user, usually due to the Tweet’s author having protected their Tweets.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*The additional data corresponding to all the tweets in the dataframe are available in tweet_json.txt file. The next step is to read the file and get the required data from JSONs (corresponding to each of the tweets). Finally, store the data in a new dataframe.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>7493</td>\n",
       "      <td>145959</td>\n",
       "      <td>8875964</td>\n",
       "      <td>Tue Aug 01 16:23:56 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>5560</td>\n",
       "      <td>145959</td>\n",
       "      <td>8875964</td>\n",
       "      <td>Tue Aug 01 00:17:27 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>3681</td>\n",
       "      <td>145959</td>\n",
       "      <td>8875964</td>\n",
       "      <td>Mon Jul 31 00:18:03 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>7662</td>\n",
       "      <td>145959</td>\n",
       "      <td>8875964</td>\n",
       "      <td>Sun Jul 30 15:58:51 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>8275</td>\n",
       "      <td>145959</td>\n",
       "      <td>8875964</td>\n",
       "      <td>Sat Jul 29 16:00:24 +0000 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  retweet_count  favourites_count  followers_count  \\\n",
       "0  892420643555336193           7493            145959          8875964   \n",
       "1  892177421306343426           5560            145959          8875964   \n",
       "2  891815181378084864           3681            145959          8875964   \n",
       "3  891689557279858688           7662            145959          8875964   \n",
       "4  891327558926688256           8275            145959          8875964   \n",
       "\n",
       "                       created_at  \n",
       "0  Tue Aug 01 16:23:56 +0000 2017  \n",
       "1  Tue Aug 01 00:17:27 +0000 2017  \n",
       "2  Mon Jul 31 00:18:03 +0000 2017  \n",
       "3  Sun Jul 30 15:58:51 +0000 2017  \n",
       "4  Sat Jul 29 16:00:24 +0000 2017  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_data = []\n",
    "\n",
    "# opening the tweet_json.txt file in read mode \n",
    "with open('tweet_json.txt', 'r') as infile:\n",
    "    # looping over each line of the file\n",
    "    for record in infile:\n",
    "        # convert string to JSON\n",
    "        record_json_data = json.loads(record)\n",
    "        # storing the required additional details in a list and appending it to the additional_data list\n",
    "        additional_data.append([record_json_data['id'], record_json_data['retweet_count'], record_json_data['user']['favourites_count'], record_json_data['user']['followers_count'], record_json_data['created_at']])\n",
    "\n",
    "# creating a new dataframe using the additional_data list of lists \n",
    "additional_data_df = pd.DataFrame(additional_data)\n",
    "# defining the column names of the dataframe\n",
    "additional_data_df.columns = ['tweet_id', 'retweet_count', 'favourites_count', 'followers_count', 'created_at']\n",
    "additional_data_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Checking the number of records to confirm that all valid records in twitter_archive_df dataframe have a corresponding record in additional_data_df dataframe.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2331, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*We observe that except for the 25 tweet IDs that are not valid, there is one record for each tweet in the dataframe. The data gathering step is now complete.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assess'></a>\n",
    "## Assessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='analyze&visualize'></a>\n",
    "## Analyze and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*CONCLUDING REMARKS:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*REFERENCES:*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_wrangling",
   "language": "python",
   "name": "data_wrangling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
